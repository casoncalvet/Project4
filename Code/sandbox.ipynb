{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710d7846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imessage_reader import fetch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "ed001c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sqlalc\n",
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55d312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_messages():\n",
    "    fd = fetch_data.FetchData()\n",
    "    messages  = fd.get_messages()\n",
    "    return messages\n",
    "\n",
    "messages= get_messages()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9607193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_friend(name): \n",
    "    \"\"\"\n",
    "    Get messages sent from friends\n",
    "    \"\"\"\n",
    "    friends = { 'Julia': '+12545412303', 'Bella': '+19016522520', \n",
    "               'Kellyn': '+19015171741', 'Dulce': '+19015749606', \n",
    "               'Faith': '+16625010261', 'Claire': '+19012582198', \n",
    "               'Mary Caroline': '+19014814783', 'Megan': '+19016741494'}\n",
    "    messages_= []\n",
    "    \n",
    "    for i in messages: \n",
    "        if i[0] == friends[name] and i[1] is not None : \n",
    "            messages_.append(i[1])\n",
    "    return messages_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd8e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_messages_df(): \n",
    "\n",
    "    data = {'Name':['Kellyn', 'Faith', 'Mary Caroline', 'Claire', 'Megan', 'Bella', 'Dulce', 'Julia'],\n",
    "            'Messages':[Kellyn, Faith, Mary_Caroline, Claire, Megan, Bella, Dulce, Julia]}\n",
    "    df1= pd.DataFrame(data)\n",
    "\n",
    "    df1.to_csv(r'/Users/casonberkenstock/Project4/Messages.csv', index = False)\n",
    "\n",
    "    df2= pd.read_csv('/Users/casonberkenstock/Project4/Messages.csv')\n",
    "    \n",
    "    return df2\n",
    "df2= get_messages_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a64df3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= pd.read_csv('/Users/casonberkenstock/Project4/Messages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8221fa80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Alter Messages table for use\n",
    "\n",
    "df2['Message']= df2[\"Messages\"].str.split(\",\")\n",
    "df2.drop(['Messages'], axis = 1, inplace = True) \n",
    "df2.rename({'Message': 'Messages'}, inplace= True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f96b7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    " \n",
    "# create a reference\n",
    "# for sql library\n",
    "\n",
    "\n",
    "import sqlalchemy as alch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def connect_engine(): \n",
    "    dbName = \"Project_4\"\n",
    "    password= 'admin'\n",
    "    connection_data= f'mysql+pymysql://root:{password}@localhost/{dbName}'\n",
    "    engine = sqlalc.create_engine(connection_data)\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "e4504132",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine= connect_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3efac1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "password= os.getenv(\"SQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "31582696",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def iMessages_to_sql(): \n",
    "    for index, row in df2.iterrows():\n",
    "        mensaje = row['Messages']\n",
    "        nombre = row['Name']\n",
    "        engine.execute(f\"\"\"insert into iMessages (Name, Messages) VALUES (%s, %s)\"\"\", (nombre, mensaje))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "231ca202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iMessages_to_sql():\n",
    "    \"\"\"\n",
    "    Import cleaned (tokenized) messages to SQL \n",
    "    \"\"\"\n",
    "    \n",
    "    for index, row in IMESSAGES.iterrows():\n",
    "        mensaje = row['Messages_clean']\n",
    "        nombre = row['Name']\n",
    "        engine.execute(f\"\"\"insert into iMessages (Name, Messages) VALUES (%s, %s)\"\"\", (nombre, mensaje))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4a712a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(dataFrme): \n",
    "    \n",
    "    nlp  = spacy.load(\"en_core_web_sm\")\n",
    "    stop = nlp.Defaults.stop_words\n",
    "    dataFrme[dataFrme.columns[0]+'_clean'] = ''\n",
    "    \n",
    "    for i in dataFrme.index:\n",
    "        new_list = []\n",
    "        for element in dataFrme.loc[i][dataFrme.columns[0]].split(','):\n",
    "            if element not in stop:\n",
    "                new_list.append(element)\n",
    "        string_without_stop = \" \".join(new_list)\n",
    "        dataFrme.loc[i][dataFrme.columns[0]] = string_without_stop\n",
    "        \n",
    "        ### 2nd part\n",
    "        filtered=[]\n",
    "        for token in nlp(string_without_stop):\n",
    "            lemma = token.lemma_.lower().strip()\n",
    "            if re.search('^[a-zA-Z]+$',lemma): # This will remove the question marks\n",
    "                filtered.append(lemma)\n",
    "        dataFrme.loc[i][dataFrme.columns[0]+'_clean'] = \" \".join(filtered)\n",
    "        \n",
    "    return dataFrme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "26684c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imessages= tokenizer(iMessages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "25d67ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "iMessages.to_csv('/Users/casonberkenstock/Project4/i_Messages.csv', index = True) # False: not include index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "ff0fbfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sql file and Set index to name for Tokenizer function \n",
    "\n",
    "query = \"SELECT * FROM iMessages\"\n",
    "iMessages = pd.read_sql_query(query, engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "9cf9f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index to Name for tokenizer function, but not necessary afterwards \n",
    "iMessages.set_index('Name', drop= True, inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "bca8ada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMESSAGES= pd.read_csv('/Users/casonberkenstock/Project4/i_messages.csv', index_col='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e55b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Had to reset index to upload final TOKENIZED df to sql \n",
    "IMESSAGES.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ff9463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that database created and uploaded into SQL, can continue NLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "e7053433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.04779406203569673, subjectivity=0.5442939470659395)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bella_blob = TextBlob(iMessages.loc['Bella'][0])\n",
    "Bella_blob.sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fb6a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that saves the sentiment of each in a df \n",
    "\n",
    "for i in dataFrme.index:\n",
    "    new_list = {}\n",
    "    for element in dataFrme.loc[i][dataFrme.columns[0]]:\n",
    "        TextBlob(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "38544c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(dtfr): \n",
    "    \"\"\"\n",
    "    Apply Sentiment Analysis Using TextBlob() to each string value in a df. Returns sentiment analysis\n",
    "    \"\"\"\n",
    "    new_dict= {}\n",
    "    for i in dtfr.index:  \n",
    "        new_dict[i]= TextBlob(dtfr.loc[i][dtfr.columns[0]]).sentiment\n",
    "    \n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "bc9a4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polarity_scores(dtfr): \n",
    "    \"\"\"\n",
    "    Apply Polarity Analysis Using sia.polarity_scores to each string value in a df. Returns sentiment analysis\n",
    "    \"\"\"\n",
    "    pol_dict= {}\n",
    "    for i in dtfr.index:  \n",
    "        pol_dict[i]= sia.polarity_scores(dtfr.loc[i][dtfr.columns[0]])\n",
    "    \n",
    "    return pol_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "1292b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dict= get_sentiment(iMessages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "0206fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_dict=get_polarity_scores(iMessages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "055407ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bella': {'neg': 0.142, 'neu': 0.681, 'pos': 0.177, 'compound': 1.0},\n",
       " 'Claire': {'neg': 0.116, 'neu': 0.726, 'pos': 0.159, 'compound': 1.0},\n",
       " 'Dulce': {'neg': 0.106, 'neu': 0.708, 'pos': 0.186, 'compound': 1.0},\n",
       " 'Faith': {'neg': 0.106, 'neu': 0.638, 'pos': 0.256, 'compound': 1.0},\n",
       " 'Julia': {'neg': 0.105, 'neu': 0.673, 'pos': 0.221, 'compound': 1.0},\n",
       " 'Kellyn': {'neg': 0.127, 'neu': 0.684, 'pos': 0.189, 'compound': 1.0},\n",
       " 'Mary Caroline': {'neg': 0.117,\n",
       "  'neu': 0.673,\n",
       "  'pos': 0.21,\n",
       "  'compound': 0.9998},\n",
       " 'Megan': {'neg': 0.079, 'neu': 0.687, 'pos': 0.234, 'compound': 1.0}}"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "3e491734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bella': Sentiment(polarity=0.04779406203569673, subjectivity=0.5442939470659395),\n",
       " 'Claire': Sentiment(polarity=0.1200657708591144, subjectivity=0.5000946215806904),\n",
       " 'Dulce': Sentiment(polarity=0.08281485202688636, subjectivity=0.4959084086877786),\n",
       " 'Faith': Sentiment(polarity=0.11855555783728274, subjectivity=0.5244034854562426),\n",
       " 'Julia': Sentiment(polarity=0.09207364394864387, subjectivity=0.5267742822294454),\n",
       " 'Kellyn': Sentiment(polarity=0.05411492263037223, subjectivity=0.5417152325497698),\n",
       " 'Mary Caroline': Sentiment(polarity=0.1265184225803695, subjectivity=0.5588947434080181),\n",
       " 'Megan': Sentiment(polarity=0.15249359163955434, subjectivity=0.5888315385442715)}"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_dict\n",
    "# Most negative, Bella, most opinionated: Megan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4bff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create env\n",
    "# activate\n",
    "\n",
    "# instalar ipykernel\n",
    "# instalar el kernel concreto de tu entorno\n",
    "\n",
    "\n",
    "# pip install de lo que quieras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faf74ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#RECIPIENT_NUMBER = \"+19014090633\" # I suggest adding yours initially to test\n",
    "#MESSAGE = \"Whats up doc\"\n",
    "\n",
    "#os.system(\"osascript sendMessage.applescript {} {}\".format(RECIPIENT_NUMBER, MESSAGE))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ironhack",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
